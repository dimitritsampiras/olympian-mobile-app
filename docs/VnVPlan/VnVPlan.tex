\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{enumitem, amssymb}
\usepackage{changepage}
\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}
\hypersetup{
	colorlinks,
	citecolor=blue,
	filecolor=black,
	linkcolor=red,
	urlcolor=blue
}
\usepackage[round]{natbib}

\input{../Comments}
\input{../Common}

\begin{document}
	
	\title{Project Title: System Verification and Validation Plan for \progname{}} 
	\author{\authname}
	\date{\today}
	
	\maketitle
	
	\pagenumbering{roman}
	
	\section{Revision History}
	
	\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
		\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
		\midrule
		Date 1 & 1.0 & Notes\\
		Date 2 & 1.1 & Notes\\
		\bottomrule
	\end{tabularx}
	
	\newpage
	
	\tableofcontents
	
	\listoftables
	\wss{Remove this section if it isn't needed}
	
	\listoffigures
	\wss{Remove this section if it isn't needed}
	
	\newpage
	
	\section{Symbols, Abbreviations and Acronyms}
	
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{l l} 
		\toprule		
		\textbf{symbol} & \textbf{description}\\
		\midrule 
		T & Test\\
		\bottomrule
	\end{tabular}\\
	
	\wss{symbols, abbreviations or acronyms --- you can simply reference the SRS
		\citep{SRS} tables, if appropriate}
	
	\wss{Remove this section if it isn't needed}
	
	\newpage
	
	\pagenumbering{arabic}
	
	This document ... \wss{provide an introductory blurb and roadmap of the
		Verification and Validation plan}
	
	\section{General Information}
	
	\subsection{Summary}
	
	%\wss{Say what software is being tested.  Give its name and a brief overview of
	%	its general functions.}
	
	The software being tested is a mobile application called Olympian. It is a workout application with a social component.
	Important components of the software that will be getting tested are:

	\begin{itemize}
		\item The functionality to log in and sign up new users. This will function to allow users to create a customized experience with data being saved over between uses.
		\item The functionality for users to create and upload their own workouts. Specifically, users should be able to set a workout category, outline steps for their workout plan, and include videos and images to support the exercise.
		\item The functionality for users to discover new and popular workouts that have been created by other users. Users should be able to sort by new or trending and filter by the muscle groups that they would like to target.
	\end{itemize}
	
	\subsection{Objectives}
	
	%\wss{State what is intended to be accomplished.  The objective will be around
	%	the qualities that are most important for your project.  You might have
	%	something like: ``build confidence in the software correctness,''
	%	``demonstrate adequate usability.'' etc.  You won't list all of the qualities,
	%	just those that are most important.}

		\begin{itemize}
			\item Demonstrate ease of use for new users to sign in.
			\item Show off intuitiveness and learnability of the workout creation process.
			\item Demonstrate usability of workout feed. Newly created workouts must appear in this feed.
			\item Support the claim that our client shall update the server and vice versa in under 10 seconds under average North American internet speeds.
		\end{itemize}

	\subsection{Relevant Documentation}
	
	%\wss{Reference relevant documentation.  This will definitely include your SRS
	%	and your other project documents (design documents, like MG, MIS, etc).  You
	%	can include these even before they are written, since by the time the project
	%	is done, they will be written.}
	
	\citet{SRS}
	\newline
	\citet{MIS}
	\newline
	\citet{MG}
	
	\section{Plan}

	This section contains the criteria for reviewing and verifying the various artifacts involved with the project.
	
	% \wss{Introduce this section.   You can provide a roadmap of the sections to
	% 	come.}
	
	\subsection{Verification and Validation Team}

	% \wss{Your teammates.  Maybe your supervisor.
	% 	You shoud do more than list names.  You should say what each person's role is
	% 	for the project's verification.  A table is a good way to summarize this information.}

	\begin{center}
		\begin{tabular}{ |c|c| } 
			\hline
			\textbf{Team Member} & \textbf{Role} \\
			\hline
			Jared Bentvelsen & Integration Testing \\
			\hline 
			Yuvraj Randhawa & Integration Testing \\
			\hline
			Bassel Rezkalla & Functional Unit Testing \\
			\hline
			Matthew McCracken & Non Functional Unit Testing \\
			\hline
			Dimitri Tsampiras & UI/UX Verification Testing \\
			\hline 
			William Lee & Code Quality and Optimization Verification\\
			\hline
		\end{tabular}
	\end{center}
	
	\subsection{SRS Verification Plan}
	% \wss{List any approaches you intend to use for SRS verification.  This may include
	% 	ad hoc feedback from reviewers, like your classmates, or you may plan for 
	% 	something more rigorous/systematic.}
	% \wss{Maybe create an SRS checklist?}

	The SRS will be evaluated by team members and classmates as the project progresses. It will also be verified through testing with a traceability matrix.
	GitHub issues left by other groups will be carefully considered and addressed.
	The following checklist will be used:
	\begin{todolist}
		\item Can the system clearly demonstrate each requirement?
		\item Can the system demonstrate each requirement outside of a testing or debugging environment?
		\item Does each requirement map to one or more tests?
	\end{todolist}
	
	\subsection{Design Verification Plan}
	% \wss{Plans for design verification}
	% \wss{The review will include reviews by your classmates}
	% \wss{Create a checklists?}

	The project design will be manually reviewed by each team member and classmates. The following checklist will be used:
	\begin{todolist}
		\item Does the system design allow for each functional and non functional requirement to be met?
		\item Does the chosen architecture(s) make sense for the given use cases? Does it allow for easy scalability?
		\item Does the design follow appropriate design principles (e.g. low coupling, high cohesion, separation of concerns)?
	\end{todolist}
	
	\subsection{Verification and Validation Plan Verification Plan}
	% \wss{The verification and validation plan is an artifact that should also be verified.}
	% \wss{The review will include reviews by your classmates}
	% \wss{Create a checklists?}

	The Verification and Validation Plan artifact will be read and reviewed by each team member according to the following checklist:
	\begin{todolist}
		\item Are there any missing or empty sections?
		\item Is each section complete with sufficient detail?
		\item Are there any contradictions between sections?
		\item Is the table of contents present and reflective of the document's sections?
		\item Is the revision history up to date?
		\item Are there any typos in the document?
	\end{todolist}
	GitHub issues left by other groups will be carefully considered and addressed.
	
	\subsection{Implementation Verification Plan}
	
	% \wss{You should at least point to the tests listed in this document and the unit
	% 	testing plan.}
	
	% \wss{In this section you would also give any details of any plans for static verification of
	% 	the implementation.  Potential techniques include code walkthroughs, code
	% 	inspection, static analyzers, etc.}

	Implementation Verification will be done according to the functional and non-functional tests listed in this document.
	Code additions will be thoroughly reviewed by team members in feature branches before merging with the main branch.
	Linters and formatters will be utilized to ensure code consistency.
	
	\subsection{Automated Testing and Verification Tools}
	
	See Section 3.5 of Problem Statement.
	% \wss{What tools are you using for automated testing.  Likely a unit testing
	% 	framework and maybe a profiling tool, like ValGrind.  Other possible tools
	% 	include a static analyzer, make, continuous integration tools, test coverage
	% 	tools, etc.  Explain your plans for summarizing code coverage metrics.
	% 	Linters are another important class of tools.  For the programming language
	% 	you select, you should look at the available linters.  There may also be tools
	% 	that verify that coding standards have been respected, like flake9 for
	% 	Python.}
	% \wss{If you have already done this in the development plan, you can point to
	% 	that document.}
	% \wss{The details of this section will likely evolve as you get closer to the
	% 	implementation.}
	
	\subsection{Software Validation Plan}
	% \wss{If there is any external data that can be used for validation, you should
	% 	point to it here.  If there are no plans for validation, you should state that
	% 	here.}
	% \wss{You might want to use review sessions with the stakeholder to check that
	% 	the requirements document captures the right requirements.  Maybe task based
	% 	inspection?}
	% \wss{This section might reference back to the SRS verification section.}
	No external data will be used for validation. In addition to the SRS verification checklist, meetings will be held with stakeholders to ensure
	requirements cover all desired tests.
	\section{System Test Description}
	
	\subsection{Tests for Functional Requirements}
	
	\wss{Subsets of the tests may be in related, so this section is divided into
		different areas.  If there are no identifiable subsets for the tests, this
		level of document structure can be removed.}
	
	\wss{Include a blurb here to explain why the subsections below
		cover the requirements.  References to the SRS would be good here.}
	
	\wss{It would be nice to have a blurb here to explain why the subsections below
		cover the requirements.  References to the SRS would be good here.  If a section
		covers tests for input constraints, you should reference the data constraints
		table in the SRS.}
	
	\begin{enumerate}
		
		\subsubsection{Workout Routine Tests}
		\item{\textbf{test-WR-1}}:A Workout Routine can be created
		
		Control: Manual
		
		Initial State: Application is running.
		
		Input: User inputs required data for a workout routine.
		
		Output: A workout routine is stored in the database and is accessible to the user that created it. If the user determined that the workout to be public then it should be publicly visible.
		
		Test Case Derivation: On a successful creation, the workout routine should be placed into the database.
		
		How test will be performed: This test can be preformed with a manual insertion of creating a workout routine under a test user. These results can be determined by viewing the database and scope of visibility of the created routine.
		
		Requirement(s): R1
		
		\item{\textbf{test-WR-2}}: Editing a Workout Routine
		
		Control: Manual
		
		Initial State: Application is running with an existing workout routine.
		
		Input: User edits a workout routine with new values.
		
		Output: A workout routine is updated with new values in the database and new values are visible to accessible users.
		
		Test Case Derivation: On a successful edit, the workout routine should be updated with new values database.
		
		How test will be performed: This test can be preformed with a manual edit of a workout routine under a test user.
		
		Requirement(s): R1
		
		\subsubsection{Exercise Tests}
		\item{\textbf{test-EX-1}}:Adding an Exercise to a Workout Routine

		Control: Manual
		
		Initial State: Application is running and a workout routine is in the process of being created or edited.
		
		Input: A user created exercise with the parameters required for the exercise.
		
		Output: The workout routine should include the added exercise.
		
		Test Case Derivation: Because exercises are bounded to a specific workout routine, the routine that the exercise was created under should include the new exercise.
		
		How test will be performed: Given a workout routine, an exercise will be manually added to determine if it is linked and added to the workout routine.
		
		Requirement(s): R2
		
		
		\item{\textbf{test-EX-2}}:Removing an Exercise from a Workout Routine
		
		Control: Manual
		
		Initial State: Application is running and a workout routine is in the process of being created or edited.
		
		Input: The user chooses to remove an exercise.
		
		Output: Some feedback indicating that an exercise has been removed. The workout routine no longer contains the removed exercise.
		
		Test Case Derivation: On removal of an exercise, there should be an indication towards the user notifying them of the removal. The exercise should also be deleted from the workout routine.
		
		How test will be performed: Given a workout routine, an exercise will be manually removed and checked to ensure that it no longer exists within the given workout routine.
		
		Requirement(s): R2
		
		
		\item{\textbf{test-EX-3}}:Limiting Exercises to a Workout Routine
		
		Control: Manual
		
		Initial State: Application is running and a workout routine is in the process of being created or edited.
		
		Input: The number of exercises required to reach the limit of exercises per workout routine. 
		
		Output: A notification to the user, before the limiting exercise notifying them of the limit, and preventing them from adding another exercise.
		
		Test Case Derivation: The user should be aware of the exercise limit per workout routine and should not be able to exceed it.
		
		How test will be performed: The test will be preformed by manually added exercises to a workout routine until the limit. Then upon adding the limiting input, a notification is expected.
		
		Requirement(s): R2
		
		\subsubsection{Quantifier Tests}
		\item{\textbf{test-QT-1}}:Adding Quantifiers to an Exercise
		
		Control: Manual
		
		Initial State: The application is running and an exercise is in the process of being created or edited.
		
		Input: A number and unit of measurement describing an exercise.
		
		Output: The exercise now holds the given quantifier and is displayed to the user.
		
		Test Case Derivation: On adding a quantifier to an exercise, there should be a unit of measurement and value associated with it.
		
		How test will be performed: This test will be executed by adding a quantifier to various types of exercises to ensure they correctly measure the exercise.
		
		Requirement(s): R3
		
		\item{\textbf{test-QT-2}}:Removing Quantifiers from an Exercise
		
		Control: Manual
		
		Initial State: The application is running and an exercise is in the process of being created or edited.
		
		Input: Removal of a quantifier.
		
		Output: The exercise no longer holds a quantifier and is not displayed to the user.
		
		Test Case Derivation: On removing a quantifier to an exercise, it should no longer be visible to the user.
		
		How test will be performed: This test will be executed by removing a quantifier from an exercises to ensure it does not display any quantifying information.
		
		Requirement(s): R3
		\item{\textbf{test-QT-3}}:Editing Quantifiers of an Exercise
		
		Control: Manual
		
		Initial State: The application is running and an exercise is in the process of being created or edited.
		
		Input: A number and unit of measurement describing an exercise.
		
		Output: The exercise now holds the updated quantifier.
		
		Test Case Derivation: On updating a quantifier to an exercise, there should be a new unit of measurement and/or value associated with it.
		
		How test will be performed: This test will be executed by editing a quantifier and ensuring the values are updated on completion of the edit.
		
		Requirement(s): R3
		
		\subsubsection{Publicity Tests}
		\item{\textbf{test-PB-1}}:Publicizing a Workout Routine
		
		Control: Manual
		
		Initial State: The application is running and a private workout routine is created.
		
		Input: An edit or addition to a workout routine to make it public.
		
		Output: The workout routine is declared public in the database and is now visible to all users.
		
		Test Case Derivation: This is the expected output because if the workout routine was not public before this action then it should not be visible to users. Once updating the publicity, the database should be updated and the routine should be publicly available 
		
		How test will be performed: This test will be done by manually changing the state of a workout routine and checking for a database update and viewing the routine under a different test-user.
		
		Requirement(s): R4
		
		\item{\textbf{test-PB-2}}:Privatizing a Workout Routine
		
		Control: Manual
		
		Initial State: The application is running and a public workout routine is created.
		
		Input: An edit or addition to a workout routine to make is private.
		
		Output: The workout routine is declared private in the database and is no longer visible to any user except the creator.
		
		Test Case Derivation: By privatizing a routine, it should no longer be accessible to any other user than the creator. There should also be a database update to signify this.
		
		How test will be performed: This test will be done by manually changing the state of a workout routine and checking for a database update and viewing the routine under a different test-user.
		
		Requirement(s): R4
		
		\subsubsection{Workout Routine Saving Tests}
	
		\item{\textbf{test-WS-1}}:Saving a Public Workout Routine
		
		Control: Manual
		
		Initial State: The application is running and there is a public workout routine created by another user.
		
		Input: The other user workout routine is saved.
		
		Output: The workout routine is now visible and accessible under the saved workout routines.
		
		Test Case Derivation: On saving a workout routine, it should be stored somewhere the user can access it for later use.
		
		How test will be performed: This test will be done by creating a public workout routine on one test-user. On a different test user this routine will be saved. The saved workout routines should then include the newly saved one.
		
		Requirement(s): R5
		
		\subsubsection{Browsing Workout Routine Tests}
		\item{\textbf{test-BS-1}}:Browsing Workout Routines
		
		Control: Manual
		
		Initial State: The application is running and multiple workout routines are created.
		
		Input: navigation movements to view the public workout routines.
		
		Output: Multiple public workout routines should be displayed. 
		
		Test Case Derivation: On making a routine public, it should be available to all users and also the browsing page.
		
		How test will be performed: By first adding multiple public test routines, then checking the public workout routines by browsing. There should exist routines to access and view.
		
		Requirement(s): R6
		
		\item{\textbf{test-BS-2}}:Search Workout Routines
		
		Control: Manual
		
		Initial State: The application is running and multiple workout routines are created.
		
		Input: Search string inputs to view the public workout routines.
		
		Output: Public workout routines that match the search criteria should be displayed. 
		
		Test Case Derivation: All workout routines that match a search, should be displayed.
		
		How test will be performed: By first adding multiple public test routines, then preforming a search, the routines that match the search criteria should be displayed.
		
		Requirement(s): R6
		
		\subsubsection{User Profile Tests}
		\item{\textbf{test-UP-1}}:Creating a User Profile
		
		Control: Manual
		
		Initial State: The application is running.
		
		Input: The required parameters for creating a profile.
		
		Output: The created profile is stored in a user database and the user should be logged into their profile.
		
		Test Case Derivation: On creating a profile the database must store the information. To go along with this the user must maintain the login status of the created profile.
		
		How test will be performed: On launching the application without a created profile a profile will be created. The database will then be checked to ensure the proper data matches.
		
		Requirement(s): R7
		
		\item{\textbf{test-UP-2}}:Viewing Other User Profile
		
		Control: Manual
		
		Initial State: The application is running and there exists another user profile.
		
		Input: Search criteria for the searched user profile.
		
		Output: A user profile is displayed with their public routines, fitness goals, and other public profile data.
		
		Test Case Derivation: On searching for another user the data shown should only be what is made public.
		
		How test will be performed: By creating a test-user profile then searching for it. The profile should display all public information and hide non-public information. 
		
		Requirement(s): R8
		
		\subsubsection{Fitness Goal Tests}
		
		\item{\textbf{test-FG-1}}:Creating a Fitness Goal
		
		Control: Manual
		
		Initial State: The application is running and a profile has been created or is in the process of creation.
		
		Input: A string parameter for a fitness goal and publicity options for the goal.
		
		Output: The fitness goal for the user is now updated in the database and is saved under their profile.
		
		Test Case Derivation: The fitness goals are specific to a given user so the data for fitness goals are stored under their profile data.
		
		How test will be performed: A test user will add a fitness goal and check if it is displayed on their profile.
		
		Requirement(s): R9
		
		\item{\textbf{test-FG-2}}:Progressing a Fitness Goal
		
		Control: Manual
		
		Initial State: The application is running and a fitness goal is created.
		
		Input: Progress points towards a given fitness goal at a given date.
		
		Output: The progress displayed towards a fitness goal should be visually updated and numerically updated in the database with a date.
		
		Test Case Derivation: The data for a fitness goal must be updated in the database for storage. To follow this, to goal must also be visually updated accordingly to signify progress towards the goal at the given date.
		
		How test will be performed: A test-user will create a fitness goal and add progress points towards the goal. There should be a database update and visual update to signify this change.
		
		Requirement(s): R10, R11
		
		
	\end{enumerate}
	
	\subsubsection{Area of Testing2}
	
	...
	
	\subsection{Tests for Nonfunctional Requirements}
	
	\wss{The nonfunctional requirements for accuracy will likely just reference the
		appropriate functional tests from above.  The test cases should mention
		reporting the relative error for these tests.  Not all projects will
		necessarily have nonfunctional requirements related to accuracy}
	
	\wss{Tests related to usability could include conducting a usability test and
		survey.  The survey will be in the Appendix.}
	
	\wss{Static tests, review, inspections, and walkthroughs, will not follow the
		format for the tests given below.}
	
	\subsubsection{Look and Feel Testing}
	
	
	\begin{enumerate}
		
		\item{\textbf{test-id-1}}: TEMPLATE
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s):
			
		\item{\textbf{test-LF-1}}: Style

		Type: Manual.
		
		Initial State: The application is running.
		
		Input/Condition: A survey is conducted with various user interactions with the application. 
		
		Output/Result: The survey results will record the overall style quality targeting areas such as simplicity, cleanliness and aesthetic appeal. 
		
		How test will be performed: This test will be preformed by conducting a survey to determine if test users think that the products appearance is minimal and straight forward.
		
		Requirement(s): NFR1
		
		

	
	\subsubsection{Usability and Humanity Tests}
		\item{\textbf{test-UH-1}}: Text Sizing and Visibility.
		
		Type: Manual
		
		Initial State: The application is running.
		
		Input/Condition: Various application screens are shown to users of diverse demographics.
		
		Output/Result: The survey results will give an indication for how visible application text is, and if any specific text needs adjustment.
		
		How test will be performed: A survey is conducted where users of various demographics interact with the application and are asked how visible application text is.
		
		Requirement(s): NFR2
		
		\item{\textbf{test-UH-2}}: Text Language.
		
		Type: Manual
		
		Initial State: The application is running.
		
		Input/Condition: User click input of language from dropdown menu.

		Output/Result: Language of the application changes to their users' chosen language.
		
		How test will be performed: Language dropdown will ba manually pressed and a language will be chosen. The application should change all text to the new selected language.
		
		Requirement(s): NFR3
		
		\item{\textbf{test-UH-3}}: Learnability.
		
		Type: Manual
		
		Initial State: The application is running.
		
		Input/Condition: The system is given to a group of users to use for a predetermined time period.
		
		Output/Result: The survey will give an indication of how easy or hard the system is to learn.
		
		How test will be performed: Each user will be tasked with performing a specific task within a set amount of time, and report how easy or difficult the task was to learn to perform.
		
		Requirement(s): NFR4
		
		\item{\textbf{test-UH-4}}: Understandability.
		
		Type: Manual

		Initial State: The application is running.
		
		Input/Condition: Various system outputs are shown to a group of users in a survey.
		
		Output/Result: The survey will give an indication of how easy or hard system output is to understand.
		
		How test will be performed: Each user in the survey is shown various system outputs and asked how easy the outputs are to understand.
		
		Requirement(s): NFR5
		
		\item{\textbf{test-UH-5}}: Hearing and Audio considerations.
		
		Type: Manual
		
		Initial State: The application is running.
		
		Input/Condition: Each system sound is played to a group of users in a survey.
		
		Output/Result: The survey will give an indication on how audible/pleasant the system sounds are.
		
		How test will be performed: System sounds will be played to users in a survey, who will respond will their perception of the audio's quality.
		
		Requirement(s): NFR6
		
		\item{\textbf{test-UH-6}}: Use of Colour and Contrast.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s): NFR7
	\subsubsection{Performance Tests}
		\item{\textbf{test-PF-1}}: Speed and Latency.
		
		Type: Dynamic
		
		Initial State: Application will be running.
		
		Input/Condition: String representing workout name and workout information.
		
		Output/Result: Inputted information updated existing program or new program created and displayed.
		
		How test will be performed: Program will be inputted and updated utilizing a testing framework that will time whether starting to completion took 10 seconds or less. 
		
		Requirement(s): NFR8
		
		\item{\textbf{test-PF-2}}: Accuracy and Precision of Quantifiers.
		
		Type: Manual
		
		Initial State: The application will be running and on the post search page.
		
		Input/Condition: Search string inputs to view public posts.
		
		Output/Result: Search results with ratings at an accuracy of 2 decimal places.
		
		How test will be performed: A string will be used to search public posts and all posts will be checked for two decimal places.
		
		Requirement(s): NFR9
		
		\item{\textbf{test-PF-3}}: Availability and Uptime
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s): NFR10
		
		\item{\textbf{test-PF-4}}: User Capacity.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s): NFR11
		
		\item{\textbf{test-PF-5}}: Scalability of User Capacity.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s): NFR12
	\subsubsection{Operational and Environment Tests}
		\item{\textbf{test-OE-1}}: Supported Systems.
		
		Type: Manual
		
		Initial State: The application is closed and the mobile device is turned on.
		
		Input/Condition: The device downloads and launches the application. All required hardware features are tested on iOS and Android devices.
		
		Output/Result: There should be complete compatibility for both supported systems without any operation system errors. 
		
		How test will be performed: This test will be done by downloading and running all features on both an iOS and Android device ensuring there are no operating system errors.
		
		Requirement(s): NFR13
	\subsubsection{Maintainability and Support Tests}
		\item{\textbf{test-MS-1}}: Maintenance.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s): NFR14
	\subsubsection{Security Tests}
		\item{\textbf{test-SEC-1}}: Private and Public Details.
		
		Type: Manual
		
		Initial State: The application will be running and logged into a user profile. 
		
		Input/Condition: Navigate to public user profiles.
		
		Output/Result: Other users profiles should not display any private details such as their passwords or email information. 
		
		How test will be performed: Search for other user profiles and verify that no private information is being displayed on their profile to other users.
		
		Requirement(s): NFR15
		
		\item{\textbf{test-SEC-2}}: Passwords.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s): NFR16
		
		\item{\textbf{test-SEC-3}}: Client Server Privacy.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
	
		Requirement(s): NFR17
		
		\item{\textbf{test-SEC-4}}: Data storage and logging.
		
		Type: Functional
		
		Initial State: Application is running 
		
		Input/Condition: A valid data entry for a workout routine or user is entered into the database.
		
		Output/Result: The entry is successfully added and there is a database recorded log of the interaction.
		
		How test will be performed: As a data point gets added, there should exist an output log for each interaction, this will be checked by viewing database logs. This will only look at valid data entries because these should get filtered out via unit testing.
		
		Requirement(s): NFR18
		
		\item{\textbf{test-SEC-5}}: Data Backups.
		
		Type: Functional, Manual
		
		Initial State: Application is running
		
		Input/Condition: Data entries exist in the database and the database fails.
		
		Output/Result: There should exist a backup of the database from a recent saved state.
		
		How test will be performed: This can be preformed manually by shutting down the database and checking if the backup is used. This can also be preformed by checking if the backup exists and is refreshed occasionally.
		
		Requirement(s): NFR18
	\subsubsection{Cultural Requirements Tests}
		\item{\textbf{test-CR-1}}: Profanity and Inappropriate Language.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s): NFR19
		
		\item{\textbf{test-CR-2}}: Reporting Offensive Language.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s): NFR20
	\subsubsection{Legal Requirements Tests}
		\item{\textbf{test-LR-1}}: Age and Gender Use.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s):NFR21
		\item{\textbf{test-LR-2}}: Data Protection.
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		Requirement(s):NFR22
	\end{enumerate}
	\subsection{Traceability Between Test Cases and Requirements}
	
	\wss{Provide a table that shows which test cases are supporting which
		requirements.}
	\newpage
		\section{Traceability Matrices and Graphs}
	
	\begin{table}[h!]
		\centering
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
			\hline
			& R1 & R2 & R3 & R4 & R5 & R6 & R7 & R8 & R9 & R10 & R11 \\ \hline
			WR1 &X & & & & & & & & & & \\ \hline
			WR2 &X & & & & & & & & & & \\ \hline
			EX1 & &X & & & & & & & & & \\ \hline 
			EX2 & &X & & & & & & & & & \\ \hline
			EX3 & &X & & & & & & & & &\\ \hline 
			QT1 & & &X & & & & & & & & \\ \hline 
			QT2 & & &X & & & & & & & & \\ \hline 
			QT3 & & &X & & & & & & & & \\ \hline 
			PB1 & & & &X & & & & & & & \\ \hline 
			PB2 & & & &X & & & & & & & \\ \hline 
			WS1 & & & & &X & & & & & & \\ \hline 
			BS1 & & & & & &X & & & & & \\ \hline 
			BS2 & & & & & &X & & & & & \\ \hline 
			UP1 & & & & & & &X & & & & \\ \hline 
			UP2 & & & & & & & &X & & & \\ \hline 
			FG1 & & & & & & & & &X & & \\ \hline 
			FG2 & & & & & & & & & &X &X \\ \hline 	
		\end{tabular}
		\caption{Functional System Tests to Functional Requirement Matrix}
		\label{Table:R_trace}
	\end{table}

\begin{table}[h!]
	\begin{adjustwidth}{-3cm}{-5cm}
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
			\hline
			& NFR1 & NFR2 & NFR3 & NFR4 & NFR5 & NFR6 & NFR7 & NFR8 & NFR9 & NFR10 & NFR11 \\ \hline
			LF1 &X & & & & & & & & & & \\ \hline
			UH1 & &X & & & & & & & & & \\ \hline
			UH2 & & &X & & & & & & & & \\ \hline
			UH3 & & & &X & & & & & & & \\ \hline 
			UH4 & & & & &X & & & & & & \\ \hline 
			UH5 & & & & & &X & & & & & \\ \hline 
			UH6 & & & & & & &X & & & & \\ \hline 
			PF1 & & & & & & & &X & & & \\ \hline 
			PF2 & & & & & & & & &X & & \\ \hline 
			PF3 & & & & & & & & & &X & \\ \hline
			PF4 & & & & & & & & & & &X \\ \hline  
		\end{tabular}
		\caption{Non-Functional System Tests to Non-Functional Requirement Matrix}
		\label{Table:R_trace}
		
				\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
			\hline
			& NFR12 & NFR13 & NFR14 & NFR15 & NFR16 & NFR17 & NFR18 & NFR19 & NFR20 & NFR21 & NFR22 \\ \hline
			PF5 &X & & & & & & & & & & \\ \hline
			OE1 & &X & & & & & & & & & \\ \hline
			MS1 & & &X & & & & & & & & \\ \hline
			SEC1 & & & &X & & & & & & & \\ \hline 
			SEC2 & & & & &X & & & & & & \\ \hline 
			SEC3 & & & & & &X & & & & & \\ \hline 
			SEC4 & & & & & &X & & & & & \\ \hline 
			SEC5 & & & & & & &X & & & & \\ \hline 
			CR1 & & & & & & & &X & & & \\ \hline 
			CR2 & & & & & & & & &X & & \\ \hline 
			LR1 & & & & & & & & & &X & \\ \hline 
			LR2 & & & & & & & & & & &X \\ \hline 
		\end{tabular}
		\caption{Non-Functional System Tests to Non-Functional Requirement Matrix}
		\label{Table:R_trace}
	\end{adjustwidth}
	\end{table}
	\section{Unit Test Description}
	
	\wss{Reference your MIS (detailed design document) and explain your overall
		philosophy for test case selection.}  
	\wss{This section should not be filled in until after the MIS (detailed design
		document) has been completed.}
	
	\subsection{Unit Testing Scope}
	
	\wss{What modules are outside of the scope.  If there are modules that are
		developed by someone else, then you would say here if you aren't planning on
		verifying them.  There may also be modules that are part of your software, but
		have a lower priority for verification than others.  If this is the case,
		explain your rationale for the ranking of module importance.}
	
	\subsection{Tests for Functional Requirements}
	
	\wss{Most of the verification will be through automated unit testing.  If
		appropriate specific modules can be verified by a non-testing based
		technique.  That can also be documented in this section.}
	
	\subsubsection{Module 1}
	
	\wss{Include a blurb here to explain why the subsections below cover the module.
		References to the MIS would be good.  You will want tests from a black box
		perspective and from a white box perspective.  Explain to the reader how the
		tests were selected.}
	
	\begin{enumerate}
		
		\item{test-id1\\}
		
		Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
			be automatic}
		
		Initial State: 
		
		Input: 
		
		Output: \wss{The expected result for the given inputs}
		
		Test Case Derivation: \wss{Justify the expected value given in the Output field}
		
		How test will be performed: 
		
		\item{test-id2\\}
		
		Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
			be automatic}
		
		Initial State: 
		
		Input: 
		
		Output: \wss{The expected result for the given inputs}
		
		Test Case Derivation: \wss{Justify the expected value given in the Output field}
		
		How test will be performed: 
		
		\item{...\\}
		
	\end{enumerate}
	
	\subsubsection{Module 2}
	
	...
	
	\subsection{Tests for Nonfunctional Requirements}
	
	\wss{If there is a module that needs to be independently assessed for
		performance, those test cases can go here.  In some projects, planning for
		nonfunctional tests of units will not be that relevant.}
	
	\wss{These tests may involve collecting performance data from previously
		mentioned functional tests.}
	
	\subsubsection{Module ?}
	
	\begin{enumerate}
		
		\item{test-id1\\}
		
		Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
			be automatic}
		
		Initial State: 
		
		Input/Condition: 
		
		Output/Result: 
		
		How test will be performed: 
		
		\item{test-id2\\}
		
		Type: Functional, Dynamic, Manual, Static etc.
		
		Initial State: 
		
		Input: 
		
		Output: 
		
		How test will be performed: 
		
	\end{enumerate}
	
	\subsubsection{Module ?}
	
	...
	
	\subsection{Traceability Between Test Cases and Modules}
	
	\wss{Provide evidence that all of the modules have been considered.}
	
	\bibliographystyle{plainnat}
	
	\bibliography{../../refs/References}
	
	\newpage
	
	\section{Appendix}
	
	This is where you can place additional information.
	
	\subsection{Symbolic Parameters}
	
	The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
	Their values are defined in this section for easy maintenance.
	
	\subsection{Usability Survey Questions?}
	
	\wss{This is a section that would be appropriate for some projects.}
	
	\newpage{}
	\section*{Appendix --- Reflection}
	
	The information in this section will be used to evaluate the team members on the
	graduate attribute of Lifelong Learning.  Please answer the following questions:
	
	\newpage{}
	\section*{Appendix --- Reflection}
	
	The information in this section will be used to evaluate the team members on the
	graduate attribute of Lifelong Learning.  Please answer the following questions:
	
	\begin{enumerate}
		\item What knowledge and skills will the team collectively need to acquire to
		successfully complete the verification and validation of your project?
		Examples of possible knowledge and skills include dynamic testing knowledge,
		static testing knowledge, specific tool usage etc.  You should look to
		identify at least one item for each team member.
		\subsection{Required Skills}
		\begin{itemize}
			\item Skill: \textbf{Static Testing}
			\\ Rationale: Static testing will be a very important part of successfully completing the verification and validation plan for many reasons. Static testing involves matching the requirements to the code. It also involves looking into code error and structure. Having a good structure to the code will help with matching requirements stated in the SRS and validation plan resulting in a more sound product.
			\\ Team member: William Lee
		\end{itemize}
		\item For each of the knowledge areas and skills identified in the previous
		question, what are at least two approaches to acquiring the knowledge or
		mastering the skill?  Of the identified approaches, which will each team
		member pursue, and why did they make this choice?
		\subsection{Acquiring Knowledge and Mastering skills}
		\begin{itemize}
			\item Skill: \textbf{Static Testing Knowledge}
			\\ Approach 1: Research and contrast various static testing methods such as walkthroughs, code reviews and inspections.
			\\ Approach 2: Refer to previous notes on Software Testing 3S03 at McMaster University regarding static testing methodology.
			\\ Verdict: William will use approach 1 to research what methods are the best catered to this project because often tutorials for testing methods go in depth on strategy for approaching static testing. With approach 2, there is only a surface knowledge level of static testing learned from the course. However approach 2 can be used as a good starting point.
		\end{itemize}
		\item Skill: \textbf{Dynamic Testing Knowledge}
		Approach 1: Consult notes from previous courses that went over software testing (SFWRENG 3S03: Software Testing) and revisit the relevant course assignments.
		Approach 2: Utilize online resources to learn and improve dynamic testing skills and abilities.
		Verdict: Yuvraj will use Approach 1 to improve his Dynamic Testing knowledge. He has chosen this strategy because the course provided relevant and detailed notes from a reputable source with a lot of background information to aid in the learning.
		\item Skill: \textbf{Integration Testing Knowledge}
		Approach 1: Review and practice integration testing from SWFRENG 3S03: Software Testing.
		Approach 2: Read online articles on integration testing and consult integration tests in well known open source products.
		Verdict: Jared will use Approach 2 to learn about integration testing since SFWRENG 3S03 did not cover it in sufficient detail to expand his skills.
	\end{enumerate}
		
	
\end{document}